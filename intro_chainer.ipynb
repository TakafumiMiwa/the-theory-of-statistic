{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro_chainer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TakafumiMiwa/the-theory-of-statistic/blob/master/intro_chainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pip5Y96RBwry",
        "colab_type": "text"
      },
      "source": [
        "### [1] Chanier のインストールとインストールの確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYXmc5JVjN2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl https://colab.chainer.org/install | sh -\n",
        "!python -c 'import chainer; chainer.print_runtime_info()'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoNaX6sDCAsQ",
        "colab_type": "text"
      },
      "source": [
        "### [2] Fashion MNIST データの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZcA6LdeCvRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from chainer.datasets.fashion_mnist import get_fashion_mnist\n",
        "train, test = get_fashion_mnist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyglJIR6DhlX",
        "colab_type": "text"
      },
      "source": [
        "### [3] データの確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05L2m05lFmXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sub functions\n",
        "import matplotlib.pyplot as plt\n",
        "LABEL_NAMES = [\n",
        "    'T-shirt/top',\n",
        "    'Trouser',\n",
        "    'Pullover',\n",
        "    'Dress',\n",
        "    'Coat',\n",
        "    'Sandal',\n",
        "    'Shirt',\n",
        "    'Sneaker',\n",
        "    'Bag',\n",
        "    'Ankle boot'\n",
        "]\n",
        "\n",
        "def get_label_name(label):\n",
        "    return LABEL_NAMES[label]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72EluXgkG3Li",
        "colab_type": "text"
      },
      "source": [
        "データの長さ，表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOaDQ2oJDOAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('train data size =', len(train))\n",
        "print('test data size =',  len(test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e-YT4lBDgcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, t = test[11]\n",
        "print('Shape of x:', x.shape)\n",
        "print('label:', t)\n",
        "print('label name:', get_label_name(t))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5E7eLK2GHju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyx0jKRFGZZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(x.reshape(28, 28), 'gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aL9InN4G_e7",
        "colab_type": "text"
      },
      "source": [
        "train データのvalidation 用に分割"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXNu90tYHEpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import chainer\n",
        "train, validation = chainer.datasets.split_dataset_random(train, 50000, seed=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NCU8FZLqP6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sub functions\n",
        "import numpy as np\n",
        "def sub_category(x):\n",
        "    tp = np.zeros(10).astype(np.float32)\n",
        "    tp[x] = 1.0\n",
        "    return tp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0MPlL4tCNR0",
        "colab_type": "text"
      },
      "source": [
        "NN part 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOgg2xG0Nqdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "from chainer import Chain\n",
        "from chainer import Variable\n",
        "from chainer import datasets\n",
        "\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# weight baias\n",
        "W1 = np.random.randn(200, 784).astype(np.float32)\n",
        "W2 = np.random.randn(10, 200).astype(np.float32)\n",
        "\n",
        "b1 = np.random.randn(200, 1).astype(np.float32)\n",
        "b2 = np.random.randn(10, 1).astype(np.float32)\n",
        "\n",
        "for t in range(len(train)):\n",
        "    x, y = train[t]\n",
        "    x = x.reshape(784, 1)\n",
        "    y = sub_category(y).reshape(10, 1)\n",
        "\n",
        "    h1 = W1.dot(x) + b1\n",
        "    h2 = np.maximum(h1, 0)\n",
        "    h3 = W2.dot(h2) + b2\n",
        "\n",
        "    loss = np.square(h3 - y).sum() / 10   # L2 squre error \n",
        "\n",
        "    h1 = h1.reshape(200, 1)\n",
        "    h2 = h2.reshape(200, 1)\n",
        "    h3 = h3.reshape(10, 1)\n",
        "\n",
        "\n",
        "    grad_L_h2 = 0.2*(h3 - y)    # L / h3\n",
        "\n",
        "    W2_grad = grad_L_h2.dot(h2.T)        # W2 weght updater\n",
        "    b2_grad = grad_L_h2                           # b2 weight  updater\n",
        "    W1_grad = grad_L_h2.T.dot(W2).T \n",
        "    W1_grad[h1 < 0] = 0                            # RELU derivativer\n",
        "    b1_grad = W1_grad                              # b1 weight updater\n",
        "    W1_grad = W1_grad.dot(x.T)             # W1 weight updater\n",
        "\n",
        "    W2 -= LEARNING_RATE * W2_grad\n",
        "    b2 -= LEARNING_RATE * b2_grad\n",
        "    W1 -= LEARNING_RATE  * W1_grad\n",
        "    b1 -= LEARNING_RATE  * b1_grad\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlSjH2bfCSVa",
        "colab_type": "text"
      },
      "source": [
        "テストケースで確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHjwexpCNAOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test \n",
        "\n",
        "for t in range(10):\n",
        "    index = np.random.randint(len(test))\n",
        "    x, y = test[index]\n",
        "    \n",
        "    x = x.reshape(784, 1)\n",
        "    y = sub_category(y).reshape(10, 1)\n",
        "\n",
        "    h1 = W1.dot(x) + b1\n",
        "    h2 = np.maximum(h1, 0)\n",
        "    h3 = W2.dot(h2) + b2\n",
        "    \n",
        "    print(\"predict\", h3.argmax(), \"true\", y.argmax())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-DZ46FmCX27",
        "colab_type": "text"
      },
      "source": [
        "NN part 2     もう少し chainer っぽく"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-CnHVfDi7Tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "from chainer import Variable\n",
        "\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "class MLP(chainer.Chain):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.l1 = L.Linear(784, 200)\n",
        "            self.l2 = L.Linear(200, 10)\n",
        "            \n",
        "    def __call__(self, x):\n",
        "        h1 = self.l1(x)\n",
        "        h2 = F.relu(h1)\n",
        "        h3 = self.l2(h2)\n",
        "        return h3\n",
        "            \n",
        "model = MLP()\n",
        "\n",
        "for t in range(len(train)):\n",
        "    x, y = train[t]\n",
        "    x = x.reshape(1, 784)\n",
        "    \n",
        "    y_p = model(x)\n",
        "    y_t = sub_category(y).reshape(1, 10)\n",
        "    \n",
        "    loss = F.mean_squared_error(y_p, y_t)\n",
        "    print(loss.data)\n",
        "    \n",
        "    model.cleargrads()\n",
        "    \n",
        "    loss.backward()\n",
        "    \n",
        "    model.l1.W.data -= LEARNING_RATE * model.l1.W.grad\n",
        "    model.l2.W.data -= LEARNING_RATE * model.l2.W.grad\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACBc1186CedE",
        "colab_type": "text"
      },
      "source": [
        "NN part 3   loss function を任意に設定できるようにclass化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRge27SkhWT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "from chainer import Chain\n",
        "from chainer import optimizers, training\n",
        "from chainer.training import extensions\n",
        "from chainer import Variable\n",
        "from chainer import reporter\n",
        "\n",
        "batchsize = 128\n",
        "n_epoch = 5\n",
        "\n",
        "def sub_cate(x, line):\n",
        "    tp = np.zeros((line, 10)).astype(np.float32)\n",
        "    for t in range(line):\n",
        "        index = np.int(x[t])\n",
        "        tp[t][index]  = 1\n",
        "    return tp\n",
        "\n",
        "# model\n",
        "class MLP(Chain):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.l1=L.Linear(784, 200)  \n",
        "            self.l2=L.Linear(200, 10)  \n",
        "\n",
        "    def __call__(self, x):\n",
        "        #h0 = x.reshape(1, 784)\n",
        "        h1 = F.relu(self.l1(x))\n",
        "        h2 = self.l2(h1) \n",
        "        return h2\n",
        "        \n",
        "class LossCalculator(chainer.Chain):\n",
        "    def __init__(self, model):\n",
        "        super(LossCalculator, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.model = model\n",
        "\n",
        "    def __call__(self, x, y): \n",
        "        y_p = self.model(x)\n",
        "        line = len(y)\n",
        "        y_t  = sub_cate(np.float32(y).reshape(line, 1), line)\n",
        "        loss = F.mean_squared_error(y_p, y_t)\n",
        "        reporter.report({'loss': loss}, self)\n",
        "        return loss\n",
        "\n",
        "    \n",
        "model1 = MLP()\n",
        "model = LossCalculator(model1)\n",
        "\n",
        "optimizer = chainer.optimizers.SGD()\n",
        "optimizer.setup(model)\n",
        "\n",
        "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
        "validation_iter = chainer.iterators.SerialIterator(validation, batchsize, repeat=False, shuffle=False)\n",
        "\n",
        "updater = training.StandardUpdater(train_iter, optimizer)\n",
        "trainer = chainer.training.Trainer(updater, (n_epoch, 'epoch'), out='out')\n",
        "trainer.extend(extensions.Evaluator(validation_iter, model))\n",
        "trainer.extend(extensions.LogReport())\n",
        "trainer.extend(extensions.PrintReport(['epoch', 'main/loss',  'validation/main/loss',  'elapsed_time']))\n",
        "    \n",
        "trainer.run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tavtqAuCpe7",
        "colab_type": "text"
      },
      "source": [
        "NN part 4  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHdm3VEzBtzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import chainer \n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "from chainer import Chain\n",
        "from chainer import optimizers, training\n",
        "from chainer.training import extensions\n",
        "\n",
        "n_epoch = 5\n",
        "batchsize = 256\n",
        "device = 0\n",
        "\n",
        "class MLP(Chain):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.l1=L.Linear(784, 200)  \n",
        "            self.l2=L.Linear(200, 10)  \n",
        "            \n",
        "    def __call__(self, x):\n",
        "        h1 = F.tanh(self.l1(x))\n",
        "        y = self.l2(h1)  \n",
        "        return y\n",
        "    \n",
        "model = L.Classifier(MLP()) \n",
        "\n",
        "if device >= 0:\n",
        "    model.to_gpu(device)\n",
        "\n",
        "optimizer = chainer.optimizers.Adam()\n",
        "optimizer.setup(model)\n",
        "\n",
        "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
        "validation_iter = chainer.iterators.SerialIterator(validation, batchsize, repeat=False, shuffle=False)\n",
        "\n",
        "updater = training.StandardUpdater(train_iter, optimizer, device=device)\n",
        "trainer = chainer.training.Trainer(updater, (n_epoch, 'epoch'), out='out')\n",
        "\n",
        "trainer.extend(extensions.LogReport())\n",
        "trainer.extend(extensions.Evaluator(validation_iter, model, device=device), name='val')\n",
        "trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'main/accuracy', 'val/main/loss', 'val/main/accuracy', 'elapsed_time']))\n",
        "trainer.extend(extensions.PlotReport(['main/loss', 'val/main/loss'],x_key='epoch', file_name='loss.png'))\n",
        "trainer.extend(extensions.PlotReport( ['main/accuracy', 'val/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
        "trainer.extend(extensions.dump_graph('main/loss'))\n",
        "\n",
        "    \n",
        "trainer.run()\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVLIOO9PKDiO",
        "colab_type": "text"
      },
      "source": [
        "CNN final "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-AofXWhGoD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import chainer \n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "from chainer import Chain\n",
        "from chainer import optimizers, training\n",
        "from chainer.training import extensions\n",
        "\n",
        "train, test = get_fashion_mnist(ndim=3)\n",
        "train, validation = chainer.datasets.split_dataset_random(train, 50000, seed=0)\n",
        "\n",
        "n_epoch = 30\n",
        "batchsize = 512\n",
        "device = 0\n",
        "\n",
        "class MLP(Chain):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.cn1 = L.Convolution2D(1, 20, 5)\n",
        "            self.cn2 = L.Convolution2D(20, 50, 5)\n",
        "            self.fc1 = L.Linear(800, 500)\n",
        "            self.fc2 = L.Linear(500, 10)\n",
        "            \n",
        "    def __call__(self, x):\n",
        "        h1 = F.max_pooling_2d(F.relu(self.cn1(x)), 2)\n",
        "        h2 = F.max_pooling_2d(F.relu(self.cn2(h1)), 2)\n",
        "        h3 = F.dropout(F.relu(self.fc1(h2)))\n",
        "        return self.fc2(h3)\n",
        "    \n",
        "    \n",
        "model = L.Classifier(MLP()) \n",
        "\n",
        "if device >= 0:\n",
        "    model.to_gpu(device)\n",
        "\n",
        "optimizer = chainer.optimizers.Adam()\n",
        "optimizer.setup(model)\n",
        "\n",
        "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
        "validation_iter = chainer.iterators.SerialIterator(validation, batchsize, repeat=False, shuffle=False)\n",
        "\n",
        "updater = training.StandardUpdater(train_iter, optimizer, device=device)\n",
        "trainer = chainer.training.Trainer(updater, (n_epoch, 'epoch'), out='out')\n",
        "\n",
        "trainer.extend(extensions.LogReport())\n",
        "trainer.extend(extensions.Evaluator(validation_iter, model, device=device), name='val')\n",
        "trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'main/accuracy', 'val/main/loss', 'val/main/accuracy', 'elapsed_time']))\n",
        "trainer.extend(extensions.PlotReport(['main/loss', 'val/main/loss'],x_key='epoch', file_name='loss.png'))\n",
        "trainer.extend(extensions.PlotReport( ['main/accuracy', 'val/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
        "trainer.extend(extensions.dump_graph('main/loss'))\n",
        "\n",
        "    \n",
        "trainer.run()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU7LL53RC4Jy",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}